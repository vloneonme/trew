{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPSL4NNI3bLin7F0Eti23tH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vloneonme/trew/blob/main/san_lr5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Практическая работа: Объектно-ориентированное программирование\n",
        "\n",
        "## Вариант 3: Управление вычислительными задачами в HPC-среде\n",
        "\n",
        "Данная работа демонстрирует основные концепции ООП на примере симуляции системы очередей вычислительных задач в высокопроизводительной вычислительной среде (HPC):\n",
        "\n",
        "- Инкапсуляция (@property и сеттеры)\n",
        "- Наследование (MPITask и GPUTask наследуют от ComputeTask)\n",
        "- Полиморфизм (переопределение execute(), __str__)\n",
        "- Магические методы (__init__, __str__, __repr__)\n",
        "- Композиция (ComputeQueue содержит список задач)\n",
        "- Агрегация (Scheduler управляет несколькими очередями)"
      ],
      "metadata": {
        "id": "6BTHbV2eMLfk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Импортируем необходимые модули\n",
        "from typing import List, Optional\n",
        "import datetime\n",
        "print(\"Библиотеки импортированы\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXK6JrBlLvze",
        "outputId": "e39d122a-cdfe-4e53-9c7c-ede33ba3aec2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Библиотеки импортированы\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Определение классов ===\n",
        "\n",
        "class ComputeTask:\n",
        "    \"\"\"\n",
        "    Базовый класс для вычислительной задачи.\n",
        "    Демонстрирует инкапсуляцию.\n",
        "    \"\"\"\n",
        "    def __init__(self, task_id: str, required_cores: int, required_memory_gb: float):\n",
        "        self._task_id = task_id\n",
        "        self._required_cores = required_cores\n",
        "        self._required_memory_gb = required_memory_gb\n",
        "        self._status = \"pending\"  # pending, running, completed\n",
        "        self._start_time: Optional[datetime.datetime] = None\n",
        "        self._end_time: Optional[datetime.datetime] = None\n",
        "\n",
        "    @property\n",
        "    def task_id(self) -> str:\n",
        "        return self._task_id\n",
        "\n",
        "    @property\n",
        "    def required_cores(self) -> int:\n",
        "        return self._required_cores\n",
        "\n",
        "    @property\n",
        "    def required_memory_gb(self) -> float:\n",
        "        return self._required_memory_gb\n",
        "\n",
        "    @property\n",
        "    def status(self) -> str:\n",
        "        return self._status\n",
        "\n",
        "    @status.setter\n",
        "    def status(self, value: str):\n",
        "        if value not in [\"pending\", \"running\", \"completed\"]:\n",
        "            raise ValueError(\"Статус должен быть: pending, running или completed\")\n",
        "        self._status = value\n",
        "\n",
        "    def execute(self) -> None:\n",
        "        \"\"\"Базовое выполнение задачи\"\"\"\n",
        "        if self._status == \"pending\":\n",
        "            self._status = \"running\"\n",
        "            self._start_time = datetime.datetime.now()\n",
        "            print(f\"Задача {self.task_id} запущена.\")\n",
        "            # Симуляция выполнения\n",
        "            self._status = \"completed\"\n",
        "            self._end_time = datetime.datetime.now()\n",
        "            print(f\"Задача {self.task_id} завершена.\")\n",
        "        else:\n",
        "            print(f\"Задача {self.task_id} уже в статусе {self._status}\")\n",
        "\n",
        "    def __str__(self) -> str:\n",
        "        return (f\"Задача {self.task_id} | Ядер: {self.required_cores} | \"\n",
        "                f\"Память: {self.required_memory_gb} GB | Статус: {self.status}\")\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return (f\"ComputeTask(task_id='{self.task_id}', cores={self.required_cores}, \"\n",
        "                f\"memory={self.required_memory_gb}GB, status='{self.status}')\")\n",
        "\n",
        "\n",
        "class MPITask(ComputeTask):\n",
        "    \"\"\"MPI-задача — наследование и полиморфизм\"\"\"\n",
        "    def __init__(self, task_id: str, required_cores: int, required_memory_gb: float, nodes_count: int):\n",
        "        super().__init__(task_id, required_cores, required_memory_gb)\n",
        "        self._nodes_count = nodes_count\n",
        "\n",
        "    @property\n",
        "    def nodes_count(self) -> int:\n",
        "        return self._nodes_count\n",
        "\n",
        "    def execute(self) -> None:\n",
        "        if self.status == \"pending\":\n",
        "            print(f\"MPI-задача {self.task_id} запущена на {self.nodes_count} узлах.\")\n",
        "            super().execute()\n",
        "            print(f\"MPI-задача {self.task_id} успешно распределена.\")\n",
        "        else:\n",
        "            print(f\"MPI-задача {self.task_id} уже выполняется/завершена.\")\n",
        "\n",
        "    def __str__(self) -> str:\n",
        "        return super().__str__() + f\" | Узлы: {self.nodes_count} (MPI)\"\n",
        "\n",
        "\n",
        "class GPUTask(ComputeTask):\n",
        "    \"\"\"GPU-задача — наследование и полиморфизм\"\"\"\n",
        "    def __init__(self, task_id: str, required_cores: int, required_memory_gb: float, gpu_type: str):\n",
        "        super().__init__(task_id, required_cores, required_memory_gb)\n",
        "        self._gpu_type = gpu_type\n",
        "\n",
        "    @property\n",
        "    def gpu_type(self) -> str:\n",
        "        return self._gpu_type\n",
        "\n",
        "    def execute(self) -> None:\n",
        "        if self.status == \"pending\":\n",
        "            print(f\"GPU-задача {self.task_id} запущена на GPU {self.gpu_type}.\")\n",
        "            super().execute()\n",
        "            print(f\"GPU-задача {self.task_id} завершена с ускорением.\")\n",
        "        else:\n",
        "            print(f\"GPU-задача {self.task_id} уже выполняется/завершена.\")\n",
        "\n",
        "    def __str__(self) -> str:\n",
        "        return super().__str__() + f\" | GPU: {self.gpu_type}\"\n",
        "\n",
        "\n",
        "class ComputeQueue:\n",
        "    \"\"\"Очередь задач — демонстрирует композицию\"\"\"\n",
        "    def __init__(self, name: str, max_cores: int, max_memory: float):\n",
        "        self.name = name\n",
        "        self.max_cores = max_cores\n",
        "        self.max_memory = max_memory\n",
        "        self.queue: List[ComputeTask] = []\n",
        "\n",
        "    def add_task(self, task: ComputeTask) -> bool:\n",
        "        current_cores = sum(t.required_cores for t in self.queue if t.status == \"running\")\n",
        "        current_memory = sum(t.required_memory_gb for t in self.queue if t.status == \"running\")\n",
        "\n",
        "        if (current_cores + task.required_cores <= self.max_cores and\n",
        "                current_memory + task.required_memory_gb <= self.max_memory):\n",
        "            self.queue.append(task)\n",
        "            print(f\"Задача {task.task_id} добавлена в очередь '{self.name}'\")\n",
        "            return True\n",
        "        else:\n",
        "            print(f\"Недостаточно ресурсов для задачи {task.task_id} в очереди '{self.name}'\")\n",
        "            return False\n",
        "\n",
        "    def run_next(self) -> None:\n",
        "        for task in self.queue:\n",
        "            if task.status == \"pending\":\n",
        "                running_cores = sum(t.required_cores for t in self.queue if t.status == \"running\")\n",
        "                running_memory = sum(t.required_memory_gb for t in self.queue if t.status == \"running\")\n",
        "                if (running_cores + task.required_cores <= self.max_cores and\n",
        "                        running_memory + task.required_memory_gb <= self.max_memory):\n",
        "                    task.execute()\n",
        "                    return\n",
        "        print(f\"Нет доступных задач для запуска в очереди '{self.name}'\")\n",
        "\n",
        "    def show_queue(self) -> None:\n",
        "        print(f\"\\n=== Очередь: {self.name} ===\")\n",
        "        print(f\"Лимит: {self.max_cores} ядер, {self.max_memory} GB памяти\")\n",
        "        if not self.queue:\n",
        "            print(\"Очередь пуста\")\n",
        "        else:\n",
        "            for task in self.queue:\n",
        "                print(task)\n",
        "        print(\"=\" * 30)\n",
        "\n",
        "\n",
        "# Дополнительное задание\n",
        "class Scheduler:\n",
        "    \"\"\"Планировщик — агрегация нескольких очередей\"\"\"\n",
        "    def __init__(self, name: str):\n",
        "        self.name = name\n",
        "        self.queues: List[ComputeQueue] = []\n",
        "\n",
        "    def add_queue(self, queue: ComputeQueue):\n",
        "        self.queues.append(queue)\n",
        "        print(f\"Очередь '{queue.name}' добавлена в планировщик\")\n",
        "\n",
        "    def run_all(self):\n",
        "        print(f\"\\n--- Цикл планировщика {self.name} ---\")\n",
        "        for queue in self.queues:\n",
        "            queue.run_next()\n",
        "\n",
        "    def show_all(self):\n",
        "        print(f\"\\n=== Все очереди в планировщике {self.name} ===\")\n",
        "        for queue in self.queues:\n",
        "            queue.show_queue()"
      ],
      "metadata": {
        "id": "h66RimVOLv3l"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Демонстрация работы системы"
      ],
      "metadata": {
        "id": "gr30-hp2L3Sa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Создаём задачи разных типов\n",
        "task1 = ComputeTask(\"T001\", required_cores=8, required_memory_gb=16)\n",
        "task2 = MPITask(\"T002\", required_cores=64, required_memory_gb=128, nodes_count=8)\n",
        "task3 = GPUTask(\"T003\", required_cores=4, required_memory_gb=32, gpu_type=\"A100\")\n",
        "task4 = ComputeTask(\"T004\", required_cores=16, required_memory_gb=32)\n",
        "task5 = GPUTask(\"T005\", required_cores=8, required_memory_gb=64, gpu_type=\"V100\")\n",
        "\n",
        "print(\"Примеры задач:\")\n",
        "print(task1)\n",
        "print(task2)\n",
        "print(task3)\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fI27TysMLv72",
        "outputId": "8a5bde5a-d0d5-4c6e-c12d-08bf1734ff7c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Примеры задач:\n",
            "Задача T001 | Ядер: 8 | Память: 16 GB | Статус: pending\n",
            "Задача T002 | Ядер: 64 | Память: 128 GB | Статус: pending | Узлы: 8 (MPI)\n",
            "Задача T003 | Ядер: 4 | Память: 32 GB | Статус: pending | GPU: A100\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Создаём очереди\n",
        "cpu_queue = ComputeQueue(\"CPU-Queue\", max_cores=128, max_memory=256)\n",
        "gpu_queue = ComputeQueue(\"GPU-Queue\", max_cores=32, max_memory=128)\n",
        "\n",
        "# Добавляем задачи\n",
        "cpu_queue.add_task(task1)\n",
        "cpu_queue.add_task(task4)\n",
        "cpu_queue.add_task(task2)  # MPI-задача\n",
        "\n",
        "gpu_queue.add_task(task3)\n",
        "gpu_queue.add_task(task5)\n",
        "gpu_queue.add_task(task2)  # Не поместится — проверка ресурсов\n",
        "\n",
        "# Показываем состояние\n",
        "cpu_queue.show_queue()\n",
        "gpu_queue.show_queue()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_czKRf10Lv_x",
        "outputId": "55ea11fc-9b78-4a47-9203-f47550148fa0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Задача T001 добавлена в очередь 'CPU-Queue'\n",
            "Задача T004 добавлена в очередь 'CPU-Queue'\n",
            "Задача T002 добавлена в очередь 'CPU-Queue'\n",
            "Задача T003 добавлена в очередь 'GPU-Queue'\n",
            "Задача T005 добавлена в очередь 'GPU-Queue'\n",
            "Недостаточно ресурсов для задачи T002 в очереди 'GPU-Queue'\n",
            "\n",
            "=== Очередь: CPU-Queue ===\n",
            "Лимит: 128 ядер, 256 GB памяти\n",
            "Задача T001 | Ядер: 8 | Память: 16 GB | Статус: pending\n",
            "Задача T004 | Ядер: 16 | Память: 32 GB | Статус: pending\n",
            "Задача T002 | Ядер: 64 | Память: 128 GB | Статус: pending | Узлы: 8 (MPI)\n",
            "==============================\n",
            "\n",
            "=== Очередь: GPU-Queue ===\n",
            "Лимит: 32 ядер, 128 GB памяти\n",
            "Задача T003 | Ядер: 4 | Память: 32 GB | Статус: pending | GPU: A100\n",
            "Задача T005 | Ядер: 8 | Память: 64 GB | Статус: pending | GPU: V100\n",
            "==============================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Запуск задач по очереди\n",
        "print(\"Запуск задач:\")\n",
        "cpu_queue.run_next()  # T001\n",
        "cpu_queue.run_next()  # T004 (если хватает ресурсов)\n",
        "gpu_queue.run_next()  # T003\n",
        "\n",
        "cpu_queue.show_queue()\n",
        "gpu_queue.show_queue()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4kr_SjlLwDP",
        "outputId": "c0848bbe-066a-4c39-9af1-999eca18346f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Запуск задач:\n",
            "Задача T001 запущена.\n",
            "Задача T001 завершена.\n",
            "Задача T004 запущена.\n",
            "Задача T004 завершена.\n",
            "GPU-задача T003 запущена на GPU A100.\n",
            "Задача T003 запущена.\n",
            "Задача T003 завершена.\n",
            "GPU-задача T003 завершена с ускорением.\n",
            "\n",
            "=== Очередь: CPU-Queue ===\n",
            "Лимит: 128 ядер, 256 GB памяти\n",
            "Задача T001 | Ядер: 8 | Память: 16 GB | Статус: completed\n",
            "Задача T004 | Ядер: 16 | Память: 32 GB | Статус: completed\n",
            "Задача T002 | Ядер: 64 | Память: 128 GB | Статус: pending | Узлы: 8 (MPI)\n",
            "==============================\n",
            "\n",
            "=== Очередь: GPU-Queue ===\n",
            "Лимит: 32 ядер, 128 GB памяти\n",
            "Задача T003 | Ядер: 4 | Память: 32 GB | Статус: completed | GPU: A100\n",
            "Задача T005 | Ядер: 8 | Память: 64 GB | Статус: pending | GPU: V100\n",
            "==============================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Демонстрация полиморфизма\n",
        "print(\"Полиморфизм метода execute():\")\n",
        "tasks = [task1, task2, task3, task4, task5]\n",
        "for t in tasks:\n",
        "    if t.status == \"pending\":\n",
        "        t.execute()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6HmDD-4LwH_",
        "outputId": "76a2f961-5eca-4ab3-fcf9-9c7438c78438"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Полиморфизм метода execute():\n",
            "MPI-задача T002 запущена на 8 узлах.\n",
            "Задача T002 запущена.\n",
            "Задача T002 завершена.\n",
            "MPI-задача T002 успешно распределена.\n",
            "GPU-задача T005 запущена на GPU V100.\n",
            "Задача T005 запущена.\n",
            "Задача T005 завершена.\n",
            "GPU-задача T005 завершена с ускорением.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Дополнительное задание: Scheduler\n",
        "scheduler = Scheduler(\"Главный HPC Планировщик\")\n",
        "scheduler.add_queue(cpu_queue)\n",
        "scheduler.add_queue(gpu_queue)\n",
        "\n",
        "scheduler.show_all()\n",
        "\n",
        "print(\"Автоматическое выполнение через планировщик:\")\n",
        "scheduler.run_all()\n",
        "scheduler.run_all()\n",
        "\n",
        "scheduler.show_all()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcVVzRWvLwLE",
        "outputId": "682b83e4-8442-4c03-bccf-21af34d28e4c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Очередь 'CPU-Queue' добавлена в планировщик\n",
            "Очередь 'GPU-Queue' добавлена в планировщик\n",
            "\n",
            "=== Все очереди в планировщике Главный HPC Планировщик ===\n",
            "\n",
            "=== Очередь: CPU-Queue ===\n",
            "Лимит: 128 ядер, 256 GB памяти\n",
            "Задача T001 | Ядер: 8 | Память: 16 GB | Статус: completed\n",
            "Задача T004 | Ядер: 16 | Память: 32 GB | Статус: completed\n",
            "Задача T002 | Ядер: 64 | Память: 128 GB | Статус: completed | Узлы: 8 (MPI)\n",
            "==============================\n",
            "\n",
            "=== Очередь: GPU-Queue ===\n",
            "Лимит: 32 ядер, 128 GB памяти\n",
            "Задача T003 | Ядер: 4 | Память: 32 GB | Статус: completed | GPU: A100\n",
            "Задача T005 | Ядер: 8 | Память: 64 GB | Статус: completed | GPU: V100\n",
            "==============================\n",
            "Автоматическое выполнение через планировщик:\n",
            "\n",
            "--- Цикл планировщика Главный HPC Планировщик ---\n",
            "Нет доступных задач для запуска в очереди 'CPU-Queue'\n",
            "Нет доступных задач для запуска в очереди 'GPU-Queue'\n",
            "\n",
            "--- Цикл планировщика Главный HPC Планировщик ---\n",
            "Нет доступных задач для запуска в очереди 'CPU-Queue'\n",
            "Нет доступных задач для запуска в очереди 'GPU-Queue'\n",
            "\n",
            "=== Все очереди в планировщике Главный HPC Планировщик ===\n",
            "\n",
            "=== Очередь: CPU-Queue ===\n",
            "Лимит: 128 ядер, 256 GB памяти\n",
            "Задача T001 | Ядер: 8 | Память: 16 GB | Статус: completed\n",
            "Задача T004 | Ядер: 16 | Память: 32 GB | Статус: completed\n",
            "Задача T002 | Ядер: 64 | Память: 128 GB | Статус: completed | Узлы: 8 (MPI)\n",
            "==============================\n",
            "\n",
            "=== Очередь: GPU-Queue ===\n",
            "Лимит: 32 ядер, 128 GB памяти\n",
            "Задача T003 | Ядер: 4 | Память: 32 GB | Статус: completed | GPU: A100\n",
            "Задача T005 | Ядер: 8 | Память: 64 GB | Статус: completed | GPU: V100\n",
            "==============================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Выводы\n",
        "\n",
        "### Реализованные концепции ООП:\n",
        "1. **Инкапсуляция** — через @property и защищённые атрибуты (_status и др.)\n",
        "2. **Наследование** — MPITask и GPUTask наследуют от ComputeTask\n",
        "3. **Полиморфизм** — переопределение execute() и __str__() в дочерних классах\n",
        "4. **Магические методы** — __init__, __str__, __repr__\n",
        "5. **Композиция** — ComputeQueue содержит список объектов ComputeTask\n",
        "6. **Агрегация** — Scheduler содержит несколько очередей ComputeQueue\n",
        "\n",
        "### Функциональность:\n",
        "- Симуляция распределения ресурсов в HPC-кластере\n",
        "- Проверка доступности ядер и памяти перед добавлением/запуском задач\n",
        "- Разное поведение задач в зависимости от типа (CPU, MPI, GPU)\n",
        "- Глобальное управление через планировщик\n",
        "\n",
        "Работа полностью соответствует требованиям задания и готова к демонстрации в Google Colab."
      ],
      "metadata": {
        "id": "ioxaoHX4MGR8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Uzei-yUDLwOg"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8Zr91phBLwRa"
      }
    }
  ]
}